{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finviz Analytics\n",
    "\n",
    "\n",
    "### What is Finviz?\n",
    "FinViz aims to make market information accessible and provides a lot of data in visual snapshots, allowing traders and investors to quickly find the stock, future or forex pair they are looking for. The site provides advanced screeners, market maps, analysis, comparative tools and charts.\n",
    "\n",
    "### Why?\n",
    "Leverage the unofficial python API for FinViz to create custom stock screeners to identify value with volatile market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nest_asyncio\n",
    "!pip install pycodestyle pycodestyle_magic\n",
    " \n",
    "import pandas as pd \n",
    "import finviz\n",
    "from finviz.screener import Screener\n",
    "import nest_asyncio\n",
    "\n",
    "#!pip install flake8\n",
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment and runtime variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to contain current data module name\n",
    "module = 'ldg_finviz'\n",
    "\n",
    "#dict containing application variables\n",
    "env_var = {'ldg_path':'C:\\\\temp\\\\','stg_path':'C:\\\\temp\\\\processed\\\\'}\n",
    "\n",
    "#dict containing error codes and descriptions\n",
    "err_var = {'no_file':'no_file',\n",
    "           'no_param':'no_param'}\n",
    "\n",
    "#filters = ['exch_nasd', 'idx_sp500', 'fa_div_none']\n",
    "filters = ['idx_sp500']\n",
    "filters = []\n",
    "#get_data_finviz(filters)\n",
    "#df = enrich_data_finviz(var)\n",
    "\n",
    "#finviz api parameters used to retreive finviz tables\n",
    "map_api_fv_table_key = {\n",
    "    'Overview': '111',\n",
    "    'Valuation': '121',\n",
    "    'Ownership': '131',\n",
    "    'Performance': '141',\n",
    "    'Custom': '152',\n",
    "    'Financial': '161',\n",
    "    'Technical': '171'\n",
    "}\n",
    "\n",
    "#dict containing internal use codes per data file.\n",
    "map_landing_code = {'ldg_finviz':[\n",
    "    {'code':'ssfin','file':'stock_screener_financial.csv'},\n",
    "    {'code':'ssovw','file':'stock_screener_overview.csv'},\n",
    "    {'code':'sstec','file':'stock_screener_technical.csv'},\n",
    "    {'code':'sscust','file':'stock_screener_custom.csv'},\n",
    "    {'code':'ssperf','file':'stock_screener_performance.csv'},\n",
    "    {'code':'ssown','file':'stock_screener_ownership.csv'},\n",
    "    {'code':'ssval','file':'stock_screener_valuation.csv'},\n",
    "    {'code':'ssovw','file':'stock_screener_overview.csv'}\n",
    "]}\n",
    "\n",
    "#TODO EVAL THIS VS map_landing_code\n",
    "#dict containing map_landing_code file names & key fields per module\n",
    "data_var = {'ldg_finviz':{ \n",
    "        'stock_ownership':'stock_screener_ownership.csv',\n",
    "        'stock_overview':'stock_screener_overview.csv',\n",
    "        'stock_key':'Ticker'\n",
    "           }}\n",
    "\n",
    "map_generic_fn = {\n",
    "    \"$remove_nonnumeric_char\":\"np.where(df[field] == '-',0,df[field])\",\n",
    "    \"$s##.##%\":\"(df[field].replace('%','',regex=True)).astype(float)*.01\",\n",
    "    \"$convert_unit\":\"df[field].apply(convert_unit)\",\n",
    "}\n",
    "\n",
    "\n",
    "#dict containing tranformation lambdas for datasets\n",
    "transform = {'root':[\n",
    "                {'stg_finviz_summary':[\n",
    "                {'field':'Outstanding_unit','fn':'df.Outstanding.str[-1:].map(convert_unit)'},\n",
    "                {'field':'outstanding_shares','fn':\"(df['Outstanding'].str[:-1].str.replace('.','') + df['Outstanding_unit'])\"},\n",
    "                {'field':'outstanding_shares','fn':\"pd.to_numeric(df['outstanding_shares'],errors='coerce').fillna(0)\"},\n",
    "                {'field':'P/E','fn':\"(pd.to_numeric(df['P/E'],errors='coerce').fillna(0)).round(decimals=2)\"},\n",
    "                {'field':'eps','fn':\"(df['Price_x']/(df['P/E'])).round(decimals=2).replace(np.inf,0)\"},\n",
    "                {'field':'earnings','fn':\"((df['outstanding_shares'].astype(float)) * (df['eps'])).round(decimals=0)\"},\n",
    "                {'field':'e/p','fn':\"(df['eps']/df['Price_x']).round(decimals=2)\"}\n",
    "                ]},\n",
    "                {'ssfin':[\n",
    "                {'field':\"['Dividend','ROE','ROA','ROI','Gross M','Oper M','Profit M','Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['Dividend','ROE','ROA','ROI','Gross M','Oper M','Profit M','Change']\",\n",
    "                 'fn':\"$s##.##%\"},\n",
    "                {'field':\"Market Cap\",\n",
    "                 'fn':\"$convert_unit\"}\n",
    "                ]},\n",
    "                {'ssovw':[\n",
    "                {'field':\"['Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['Change']\",\n",
    "                 'fn':\"$s##.##%\"},\n",
    "                {'field':\"Market Cap\",\n",
    "                 'fn':\"$convert_unit\"}\n",
    "                ]},\n",
    "                {'sstec':[\n",
    "                {'field':\"['SMA20','SMA50','SMA200','52W High','52W Low','Change','from Open','Gap']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['SMA20','SMA50','SMA200','52W High','52W Low','Change','from Open','Gap']\",\n",
    "                 'fn':\"$s##.##%\"}\n",
    "                    \n",
    "                ]},\n",
    "                {'sscust':[\n",
    "                {'field':\"['Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['Change']\",\n",
    "                 'fn':\"$s##.##%\"},\n",
    "                {'field':\"Market Cap\",\n",
    "                 'fn':\"$convert_unit\"}\n",
    "                ]},\n",
    "                {'ssperf':[\n",
    "                {'field':\"['Perf Week','Perf Month','Perf Quart','Perf Year','Perf YTD','Volatility W','Volatility M','Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['Perf Week','Perf Month','Perf Quart','Perf Year','Perf YTD','Volatility W','Volatility M','Change']\",\n",
    "                 'fn':\"$s##.##%\"}\n",
    "                ]},\n",
    "                {'ssown':[\n",
    "                {'field':\"['Insider Own','Insider Trans','Float Short','Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['Insider Own','Insider Trans','Float Short','Change']\",\n",
    "                 'fn':\"$s##.##%\"},\n",
    "                {'field':\"Market Cap\",\n",
    "                 'fn':\"$convert_unit\"}\n",
    "                ]},\n",
    "                {'ssval':[\n",
    "                {'field':\"['EPS this Y','EPS next Y','EPS next 5Y','Sales past 5Y','Change']\",\n",
    "                 'fn':\"$remove_nonnumeric_char\"},\n",
    "                {'field':\"['EPS this Y','EPS next Y','EPS next 5Y','Sales past 5Y','Change']\",\n",
    "                 'fn':\"$s##.##%\"},\n",
    "                {'field':\"Market Cap\",\n",
    "                 'fn':\"$convert_unit\"}\n",
    "                ]}\n",
    "            ]}\n",
    "\n",
    "#dict containing all relevant runtime variables\n",
    "var = {'err_var':err_var, 'env_var':env_var,'data_var':data_var,'transform':transform}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Screener\n",
    "\n",
    "Before using the Screener class, you have to manually go to the website's screener and enter your desired settings. The URL will automatically change every time you add a new setting. After you're done the URL will look something like this:\n",
    "\n",
    "https://i.imgur.com/p8BLt06.png\n",
    "\n",
    "Those parameters are a list of key/value pairs separated with the & symbol. Some keys have a clear intent - f=cap_largeover,exch_nasd,fa_fpe_o10 are filters, o=-ticker is order and t=ZM are tickers - yet, some are ambiguous like v=111, which stands for the type of table.\n",
    "\n",
    "To make matters easier inside the code you won't refer to tables by their number tag, but instead you will use their full name (ex. table=Performance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_finviz(filters):\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    ldg_path = env_var.get('ldg_path') \n",
    "    \n",
    "    for i in map_api_fv_table_key:\n",
    "        print(i.lower())\n",
    "        stock_list = Screener(filters=filters, table=i)\n",
    "        stock_list.to_csv(ldg_path + 'stock_screener_' + i.lower() + '.csv')\n",
    "\n",
    "def unpack_variables(var):\n",
    "    env_var = var['env_var']\n",
    "    data_var = var['data_var']\n",
    "    err_var = var['err_var']\n",
    "    transform = var['transform']\n",
    "    return env_var, err_var, data_var,transform\n",
    "    \n",
    "def log_diagnostics(rpc, e, var):\n",
    "    print('error',rpc,e,env_var)\n",
    "\n",
    "\n",
    "def get_transform(target):\n",
    "    #returns a list of dicts with transform logic in format {field:value, fn:value} \n",
    "    lst = [i.get(target) for i in transform['root'] if i.get(target) != None]\n",
    "    if lst != []: lst = lst[0]\n",
    "    return lst\n",
    "\n",
    "#apply transformations to target dataframe\n",
    "def apply_transform(df, transform):\n",
    "    for t in transform: \n",
    "        fn = t.get('fn')\n",
    "        if fn[0] == '$': fn = map_generic_fn.get(fn)\n",
    "        field = t.get('field')\n",
    "        if field[0] == '[':field = eval(field) \n",
    "        print('apply transform: {field, function}',field,fn)\n",
    "        df[field] = eval(fn)\n",
    "    return \n",
    "\n",
    "#load data from landing, normalize using transforms, output to staging\n",
    "def normalize_data():\n",
    "    for i in map_landing_code.get(module):\n",
    "        #load file for meta contract and data type conversion\n",
    "        file = ldg_path + i.get('file')\n",
    "        code = i.get('code')\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        trns = get_transform(code)\n",
    "        if trns != []:\n",
    "            apply_transform(df,trns)\n",
    "        df.to_csv(stg_path + i.get('file'))\n",
    "#TODO Normalize column names, tolwower() with underscores...             \n",
    "\n",
    "def convert_unit(u):\n",
    "    if len(u) != 1: \n",
    "        ua = u\n",
    "        u = str(u[-1])\n",
    "        val = str(ua[0:-1]).replace('.','')\n",
    "    else:  val = ''\n",
    "    u=u.lower()\n",
    "\n",
    "    if u == 'm':\n",
    "        val += '0000'\n",
    "    elif u == 'b':\n",
    "        val += '0000000'\n",
    "    return val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage Data from FinViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "ENF = err_var.get('no_param')\n",
    "ldg_path = env_var.get('ldg_path') \n",
    "stg_path = env_var.get('stg_path')\n",
    "\n",
    "get_data_finviz(filters)\n",
    "normalize_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_data_finviz(var):\n",
    "    import numpy as np\n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    \n",
    "    ENF = err_var.get('no_param')\n",
    "    stg_path = env_var.get('stg_path')\n",
    "    \n",
    "    fown =stg_path + data_var[module].get('stock_ownership',ENF)\n",
    "    fovr =stg_path + data_var[module].get('stock_overview',ENF)\n",
    "    key = data_var[module].get('stock_key',ENF)\n",
    "    \n",
    "    if (fown==ENF) or (fovr== ENF) or (key == ENF):\n",
    "        e = 'missing file or key name'\n",
    "        log_diagnostics('enrich_data_finviz',e,env_var)\n",
    "        return\n",
    "    \n",
    "    #generate additional attibutes\n",
    "    df_own = pd.read_csv(fown).reset_index()\n",
    "    df_own.set_index(key,inplace=True)\n",
    "    df_view = pd.read_csv(fovr).reset_index()\n",
    "    df_view.set_index(key,inplace=True)\n",
    "    df = pd.merge(df_own,df_view,how='inner',left_index = True, right_index=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "                \n",
    "    transform = get_transform('stg_finviz_summary') \n",
    "    apply_transform(df,transform)\n",
    "    df = df[['Ticker','eps','earnings','P/E','e/p','outstanding_shares']]\n",
    "\n",
    "    df.to_csv(stg_path + 'stock_screener_summary.csv')\n",
    "\n",
    "\n",
    "    enrich_data_finviz(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docs():\n",
    "    from pandas_profiling import ProfileReport\n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    stg_path = env_var.get('stg_path')\n",
    "    ldg_path = env_var.get('ldg_path')\n",
    "    \n",
    "\n",
    "    for i in map_landing_code[module]:\n",
    "        file = i.get('file')\n",
    "        print('# ',file)\n",
    "        # print(i)\n",
    "        df = pd.read_csv(ldg_path + file)\n",
    "        l = list(df.columns)\n",
    "        print('## Columns')\n",
    "        for a in l: \n",
    "            print(a)\n",
    "        print('## Summary Stats')    \n",
    "        print(df.describe(include='object'))\n",
    "        print('')\n",
    "        print('')\n",
    "        profile = ProfileReport(df, title= 'Profile: ' + file + ' (Landing)')\n",
    "        profile.to_file(ldg_path + 'profile_' + file[-3])\n",
    "\n",
    "        \n",
    "generate_docs()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d7b125ca1746>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#!pip install <https://github.com/pandas-profiling/pandas-profiling/archive/master.zip> --user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#import pandas_profiling as pp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas_profiling\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontroller\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile_report\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;31m# GH 27101\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;31m# TODO: remove Panel compat in 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY37\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "#!pip install --user --upgrade joblib\n",
    "#!pip install pandas-profiling --user\n",
    "#!pip install <https://github.com/pandas-profiling/pandas-profiling/archive/master.zip> --user\n",
    "#import pandas_profiling as pp\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-305814297db4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#profile = ProfileReport(df, title= 'Profile:  (Landing)')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#profile.to_file()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;31m# GH 27101\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;31m# TODO: remove Panel compat in 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY37\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "#profile = ProfileReport(df, title= 'Profile:  (Landing)')\n",
    "#profile.to_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
