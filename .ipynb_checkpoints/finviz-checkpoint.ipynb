{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finviz Analytics\n",
    "\n",
    "\n",
    "### What is Finviz?\n",
    "FinViz aims to make market information accessible and provides a lot of data in visual snapshots, allowing traders and investors to quickly find the stock, future or forex pair they are looking for. The site provides advanced screeners, market maps, analysis, comparative tools and charts.\n",
    "\n",
    "### Why?\n",
    "Leverage NRT financial stats to create custom stock screens and perspectives to identify value with in volatile market conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Prerequisites \n",
    "\n",
    "### finviz\n",
    "Finviz is a stock screener and trading tool used for creating financial displays. Professional traders frequently use this platform to save time because Finviz allows traders and investors to quickly screen and find stocks based on set criteria.\n",
    "\n",
    "\n",
    "### pandas, pandas_profiling\n",
    "Pandas needs no introduction.  Pandas_profiling creates beautiful html data profiles.\n",
    "\n",
    "### nest_asyncio\n",
    "Nest_asyncio supports asynchronous call for use with an interactive broker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import logging \n",
    "from finviz.screener import Screener\n",
    "\n",
    "log = logging.getLogger() \n",
    "console = logging.StreamHandler()\n",
    "format_str = '%(asctime)s\\t%(levelname)s -- %(processName)s -- %(message)s'\n",
    "console.setFormatter(logging.Formatter(format_str))\n",
    "log.addHandler(console) \n",
    "log.setLevel(logging.INFO) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load environment and runtime variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-19 11:01:11,923\tINFO -- MainProcess -- loaded: api_params\n",
      "2020-06-19 11:01:11,924\tINFO -- MainProcess -- loaded: data_var\n",
      "2020-06-19 11:01:11,925\tINFO -- MainProcess -- loaded: env_var\n",
      "2020-06-19 11:01:11,926\tINFO -- MainProcess -- loaded: err_var\n",
      "2020-06-19 11:01:11,927\tINFO -- MainProcess -- loaded: map_generic_fn\n",
      "2020-06-19 11:01:11,927\tINFO -- MainProcess -- loaded: map_landing_dataset_code\n",
      "2020-06-19 11:01:11,929\tINFO -- MainProcess -- loaded: transform\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "MODULE is used to identify and segment runtime and environment variables from config files.\n",
    "'''\n",
    "MODULE = 'ldg_finviz'\n",
    "\n",
    "\n",
    "'''\n",
    "Load configuration fiiles from \\config.  Instansiate variables with config file names.  \n",
    "'''\n",
    "import os \n",
    "d = os.getcwd()\n",
    "df = d + '\\\\config\\\\'\n",
    "try: \n",
    "    for i in os.listdir(df):\n",
    "        k = i[:-4] \n",
    "        v = open(df + i).read()\n",
    "        v = eval(v)\n",
    "        exec(\"%s=%s\" % (k,v))   \n",
    "        log.info('loaded: ' + k)\n",
    "except:\n",
    "    log.error('issue encountered with eval(data): ' + str(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_finviz(generate_data_profile=False):\n",
    "    '''\n",
    "    Download FinViz 15min delayed stock data.  \n",
    "    * filter - Filter stock universe using filters variable.  \n",
    "    * Select datasets to download using the map_api_fv_table_key.config  \n",
    "    * Dataset options include: \n",
    "        'Overview': '111',\n",
    "        'Valuation': '121',\n",
    "        'Ownership': '131',\n",
    "        'Performance': '141',\n",
    "        'Custom': '152',\n",
    "        'Financial': '161',\n",
    "        'Technical': '171'\n",
    "    * Refer to /docs for dataset details.\n",
    "    \n",
    "    Output data in .csv format to landing.\n",
    "    '''\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    #load variables\n",
    "    ldg_path = env_var.get('ldg_path') \n",
    "    filters = api_params['filter']\n",
    "\n",
    "    #loop through datasets to download from Screener & write to file.\n",
    "    for i in api_params['datasets']:\n",
    "        log.info('downloading:' + i.get('dataset').lower())\n",
    "        stock_list = Screener(filters=filters, table= i.get('dataset'))\n",
    "        stock_list.to_csv(ldg_path + 'stock_screener_' +  i.get('dataset').lower() + '.csv')\n",
    "    \n",
    "    if generate_data_profile == True:\n",
    "        log.info('begin pandas profile.html generation')\n",
    "        generate_docs('ldg_path')\n",
    "\n",
    "def get_transform(target):\n",
    "    '''\n",
    "    Get transform from transform.cfg for target dataset\n",
    "    #returns a list of dicts with transform logic in format {field:value, fn:value} \n",
    "    '''\n",
    "\n",
    "    lst = [i.get(target) for i in transform['root'] if i.get(target) != None]\n",
    "    if lst != []: lst = lst[0]\n",
    "\n",
    "    return lst\n",
    "\n",
    "def apply_transform(df, transform, target):\n",
    "    '''\n",
    "    apply list of tranformstions to dataframe\n",
    "    '''\n",
    "    import numpy as np\n",
    "    log.info('begin transforms for: ' + target)\n",
    "    \n",
    "    try: \n",
    "        for t in transform: \n",
    "\n",
    "            #get function to apply\n",
    "            fn = t.get('fn')    \n",
    "            #get reusable function from map_generic_fn if fn starts with $ \n",
    "            if fn[0] == '$': fn = map_generic_fn.get(fn)\n",
    "\n",
    "            #get field or fields to update\n",
    "            field = t.get('field')\n",
    "            if field[0] == '[':field = eval(field) \n",
    "            #log.info('apply transform: {field, function} ' + str(field) + ' ' + fn)\n",
    "\n",
    "            #apply transformation\n",
    "            df[field] = eval(fn)\n",
    "    except: \n",
    "        log.error('error encountered with table:' + str(target) + ' field:' + str(field) + ' fn:' + str(fn) )\n",
    "    \n",
    "    log.info('end transforms for: ' + target)\n",
    "    return \n",
    "\n",
    "def normalize_data():\n",
    "    '''\n",
    "    Perform preprocessing and copy data to staging area.  \n",
    "    Preprocessing steps are included in transform.cfg and typically include:\n",
    "    - metadata validation / data contract\n",
    "    - preliminary schema normalization\n",
    "    - data type validation & associated cleansing.  \n",
    "    '''\n",
    "    \n",
    "    ldg_path = env_var.get('ldg_path') \n",
    "    stg_path = env_var.get('stg_path')\n",
    "    \n",
    "    try:\n",
    "        #for each dataset in map_landing_dataset_code\n",
    "        for i in map_landing_dataset_code.get(MODULE):\n",
    "\n",
    "            #load file for meta contract and data type conversion\n",
    "            file = ldg_path + i.get('file')\n",
    "            code = i.get('code')\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            trns = get_transform(code)\n",
    "            if trns != []:\n",
    "                #apply transformation to dataframe\n",
    "                apply_transform(df,trns,code)\n",
    "\n",
    "            df.to_csv(stg_path + i.get('file'))\n",
    "            #TODO Normalize column names, tolwower() with underscores...             \n",
    "    except:\n",
    "        log.error('error in normalize_data()')\n",
    "        \n",
    "def generate_docs(path):\n",
    "    '''\n",
    "    generate pandas_profile.html reports\n",
    "    '''\n",
    "    from pandas_profiling import ProfileReport\n",
    "    \n",
    "    data_path = env_var.get(path)\n",
    "    \n",
    "    try: \n",
    "        for i in map_landing_dataset_code[MODULE]:\n",
    "            file = i.get('file')\n",
    "            df = pd.read_csv(data_path + file)\n",
    "            profile = ProfileReport(df, title= 'Profile: ' + file + ' (Landing)')\n",
    "            profile.to_file(data_path + 'profile_' + file[0:-4] + '.html')\n",
    "    except:\n",
    "        log.error('error in generating pandas_profile.html')\n",
    "\n",
    "def convert_unit(u):\n",
    "    if len(u) != 1: \n",
    "        ua = u\n",
    "        u = str(u[-1])\n",
    "        val = str(ua[0:-1]).replace('.','')\n",
    "    else:  val = ''\n",
    "    u=u.lower()\n",
    "\n",
    "    if u == 'm':\n",
    "        val += '0000'\n",
    "    elif u == 'b':\n",
    "        val += '0000000'\n",
    "    return val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & stage data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-19 11:01:17,476\tINFO -- MainProcess -- begin downloading finviz\n",
      "2020-06-19 11:01:17,477\tINFO -- MainProcess -- end downloading finviz\n",
      "2020-06-19 11:01:17,478\tINFO -- MainProcess -- begin finviz preprocessing\n",
      "2020-06-19 11:01:17,507\tINFO -- MainProcess -- begin transforms for: ssfin\n",
      "2020-06-19 11:01:17,515\tINFO -- MainProcess -- Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2020-06-19 11:01:17,515\tINFO -- MainProcess -- NumExpr defaulting to 8 threads.\n",
      "2020-06-19 11:01:17,607\tINFO -- MainProcess -- end transforms for: ssfin\n",
      "2020-06-19 11:01:17,708\tINFO -- MainProcess -- begin transforms for: ssovw\n",
      "2020-06-19 11:01:17,729\tINFO -- MainProcess -- end transforms for: ssovw\n",
      "2020-06-19 11:01:17,794\tINFO -- MainProcess -- begin transforms for: sstec\n",
      "2020-06-19 11:01:17,892\tINFO -- MainProcess -- end transforms for: sstec\n",
      "2020-06-19 11:01:18,001\tINFO -- MainProcess -- begin transforms for: sscust\n",
      "2020-06-19 11:01:18,023\tINFO -- MainProcess -- end transforms for: sscust\n",
      "2020-06-19 11:01:18,089\tINFO -- MainProcess -- begin transforms for: ssperf\n",
      "2020-06-19 11:01:18,186\tINFO -- MainProcess -- end transforms for: ssperf\n",
      "2020-06-19 11:01:18,300\tINFO -- MainProcess -- begin transforms for: ssown\n",
      "2020-06-19 11:01:18,421\tINFO -- MainProcess -- end transforms for: ssown\n",
      "2020-06-19 11:01:18,516\tINFO -- MainProcess -- begin transforms for: ssval\n",
      "2020-06-19 11:01:18,577\tINFO -- MainProcess -- end transforms for: ssval\n",
      "2020-06-19 11:01:18,662\tINFO -- MainProcess -- begin transforms for: ssovw\n",
      "2020-06-19 11:01:18,683\tINFO -- MainProcess -- end transforms for: ssovw\n",
      "2020-06-19 11:01:18,726\tINFO -- MainProcess -- end finviz preprocessing\n"
     ]
    }
   ],
   "source": [
    "log.info('begin downloading finviz')\n",
    "#get_data_finviz(generate_data_profile=False)\n",
    "log.info('end downloading finviz')\n",
    "\n",
    "\n",
    "log.info('begin finviz preprocessing')\n",
    "normalize_data()\n",
    "log.info('end finviz preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-19 11:01:28,134\tINFO -- MainProcess -- begin transforms for: stg_finviz_summary\n",
      "2020-06-19 11:01:28,142\tINFO -- MainProcess -- end transforms for: stg_finviz_summary\n"
     ]
    }
   ],
   "source": [
    "def enrich_data_finviz():\n",
    "    import numpy as np\n",
    "    \n",
    "    ENF = err_var.get('no_param')\n",
    "    stg_path = env_var.get('stg_path')\n",
    "    \n",
    "    fown =stg_path + data_var[MODULE].get('stock_ownership',ENF)\n",
    "    fovr =stg_path + data_var[MODULE].get('stock_overview',ENF)\n",
    "    key = data_var[MODULE].get('stock_key',ENF)\n",
    "    \n",
    "    if (fown==ENF) or (fovr== ENF) or (key == ENF):\n",
    "        e = 'missing file or key name'\n",
    "        log_diagnostics('enrich_data_finviz',e,env_var)\n",
    "        return\n",
    "    \n",
    "    #generate additional attibutes\n",
    "    df_own = pd.read_csv(fown).reset_index()\n",
    "    df_own.set_index(key,inplace=True)\n",
    "    df_view = pd.read_csv(fovr).reset_index()\n",
    "    df_view.set_index(key,inplace=True)\n",
    "    df = pd.merge(df_own,df_view,how='inner',left_index = True, right_index=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    target = 'stg_finviz_summary'            \n",
    "    transform = get_transform(target) \n",
    "    apply_transform(df,transform,target)\n",
    "    df = df[['Ticker','eps','earnings','P/E','e/p','Outstanding']]\n",
    "\n",
    "    df.to_csv(stg_path + 'stock_screener_summary.csv')\n",
    "\n",
    "\n",
    "enrich_data_finviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
