{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finviz Analytics\n",
    "\n",
    "\n",
    "### What is Finviz?\n",
    "FinViz aims to make market information accessible and provides a lot of data in visual snapshots, allowing traders and investors to quickly find the stock, future or forex pair they are looking for. The site provides advanced screeners, market maps, analysis, comparative tools and charts.\n",
    "\n",
    "### Why?\n",
    "Leverage the unofficial python API for FinViz to create custom stock screeners to identify value with volatile market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nest_asyncio\n",
    "#!pip install pycodestyle pycodestyle_magic\n",
    "#!pip install flake8\n",
    " \n",
    "import pandas as pd \n",
    "import finviz\n",
    "from finviz.screener import Screener\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment and runtime variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to contain current data module name\n",
    "module = 'ldg_finviz'\n",
    "\n",
    "#filters to reduce finviz api payload\n",
    "#filters = ['exch_nasd', 'idx_sp500', 'fa_div_none']\n",
    "filters = [] #extract all\n",
    "\n",
    "#load configs\n",
    "import os \n",
    "d = os.getcwd()\n",
    "df = d + '\\\\config\\\\'\n",
    "for i in os.listdir(df):\n",
    "    k = i[:-4] \n",
    "    v = eval(open(df + i).read())\n",
    "    exec(\"%s=%s\" % (k,v))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Screener\n",
    "\n",
    "Before using the Screener class, you have to manually go to the website's screener and enter your desired settings. The URL will automatically change every time you add a new setting. After you're done the URL will look something like this:\n",
    "\n",
    "https://i.imgur.com/p8BLt06.png\n",
    "\n",
    "Those parameters are a list of key/value pairs separated with the & symbol. Some keys have a clear intent - f=cap_largeover,exch_nasd,fa_fpe_o10 are filters, o=-ticker is order and t=ZM are tickers - yet, some are ambiguous like v=111, which stands for the type of table.\n",
    "\n",
    "To make matters easier inside the code you won't refer to tables by their number tag, but instead you will use their full name (ex. table=Performance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_finviz(filters):\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    ldg_path = env_var.get('ldg_path') \n",
    "    \n",
    "    for i in map_api_fv_table_key:\n",
    "        print(i.lower())\n",
    "        stock_list = Screener(filters=filters, table=i)\n",
    "        stock_list.to_csv(ldg_path + 'stock_screener_' + i.lower() + '.csv')\n",
    "\n",
    "def unpack_variables(var):\n",
    "    env_var = var['env_var']\n",
    "    data_var = var['data_var']\n",
    "    err_var = var['err_var']\n",
    "    transform = var['transform']\n",
    "    return env_var, err_var, data_var,transform\n",
    "    \n",
    "def log_diagnostics(rpc, e, var):\n",
    "    print('error',rpc,e,env_var)\n",
    "\n",
    "\n",
    "def get_transform(target):\n",
    "    #returns a list of dicts with transform logic in format {field:value, fn:value} \n",
    "    lst = [i.get(target) for i in transform['root'] if i.get(target) != None]\n",
    "    if lst != []: lst = lst[0]\n",
    "    return lst\n",
    "\n",
    "#apply transformations to target dataframe\n",
    "def apply_transform(df, transform):\n",
    "    for t in transform: \n",
    "        fn = t.get('fn')\n",
    "        if fn[0] == '$': fn = map_generic_fn.get(fn)\n",
    "        field = t.get('field')\n",
    "        if field[0] == '[':field = eval(field) \n",
    "        print('apply transform: {field, function}',field,fn)\n",
    "        df[field] = eval(fn)\n",
    "    return \n",
    "\n",
    "#load data from landing, normalize using transforms, output to staging\n",
    "def normalize_data():\n",
    "    for i in map_landing_code.get(module):\n",
    "        #load file for meta contract and data type conversion\n",
    "        file = ldg_path + i.get('file')\n",
    "        code = i.get('code')\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        trns = get_transform(code)\n",
    "        if trns != []:\n",
    "            apply_transform(df,trns)\n",
    "        df.to_csv(stg_path + i.get('file'))\n",
    "#TODO Normalize column names, tolwower() with underscores...             \n",
    "\n",
    "def convert_unit(u):\n",
    "    if len(u) != 1: \n",
    "        ua = u\n",
    "        u = str(u[-1])\n",
    "        val = str(ua[0:-1]).replace('.','')\n",
    "    else:  val = ''\n",
    "    u=u.lower()\n",
    "\n",
    "    if u == 'm':\n",
    "        val += '0000'\n",
    "    elif u == 'b':\n",
    "        val += '0000000'\n",
    "    return val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage Data from FinViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overview\n",
      "valuation\n",
      "ownership\n",
      "performance\n",
      "custom\n",
      "financial\n",
      "technical\n",
      "apply transform: {field, function} ['Dividend', 'ROE', 'ROA', 'ROI', 'Gross M', 'Oper M', 'Profit M', 'Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Dividend', 'ROE', 'ROA', 'ROI', 'Gross M', 'Oper M', 'Profit M', 'Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n",
      "apply transform: {field, function} ['Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n",
      "apply transform: {field, function} ['SMA20', 'SMA50', 'SMA200', '52W High', '52W Low', 'Change', 'from Open', 'Gap'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['SMA20', 'SMA50', 'SMA200', '52W High', '52W Low', 'Change', 'from Open', 'Gap'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} ['Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n",
      "apply transform: {field, function} ['Perf Week', 'Perf Month', 'Perf Quart', 'Perf Year', 'Perf YTD', 'Volatility W', 'Volatility M', 'Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Perf Week', 'Perf Month', 'Perf Quart', 'Perf Year', 'Perf YTD', 'Volatility W', 'Volatility M', 'Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} ['Insider Own', 'Insider Trans', 'Float Short', 'Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Insider Own', 'Insider Trans', 'Float Short', 'Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n",
      "apply transform: {field, function} ['EPS this Y', 'EPS next Y', 'EPS next 5Y', 'Sales past 5Y', 'Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['EPS this Y', 'EPS next Y', 'EPS next 5Y', 'Sales past 5Y', 'Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n",
      "apply transform: {field, function} ['Change'] np.where(df[field] == '-',0,df[field])\n",
      "apply transform: {field, function} ['Change'] (df[field].replace('%','',regex=True)).astype(float)*.01\n",
      "apply transform: {field, function} Market Cap df[field].apply(convert_unit)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#dict containing all relevant runtime variables\n",
    "var = {'err_var':err_var, 'env_var':env_var,'data_var':data_var,'transform':transform}\n",
    "env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "ENF = err_var.get('no_param')\n",
    "ldg_path = env_var.get('ldg_path') \n",
    "stg_path = env_var.get('stg_path')\n",
    "\n",
    "get_data_finviz(filters)\n",
    "normalize_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply transform: {field, function} Outstanding_unit df.Outstanding.str[-1:].map(convert_unit)\n",
      "apply transform: {field, function} outstanding_shares (df['Outstanding'].str[:-1].str.replace('.','') + df['Outstanding_unit'])\n",
      "apply transform: {field, function} outstanding_shares pd.to_numeric(df['outstanding_shares'],errors='coerce').fillna(0)\n",
      "apply transform: {field, function} P/E (pd.to_numeric(df['P/E'],errors='coerce').fillna(0)).round(decimals=2)\n",
      "apply transform: {field, function} eps (df['Price_x']/(df['P/E'])).round(decimals=2).replace(np.inf,0)\n",
      "apply transform: {field, function} earnings ((df['outstanding_shares'].astype(float)) * (df['eps'])).round(decimals=0)\n",
      "apply transform: {field, function} e/p (df['eps']/df['Price_x']).round(decimals=2)\n"
     ]
    }
   ],
   "source": [
    "def enrich_data_finviz(var):\n",
    "    import numpy as np\n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    \n",
    "    ENF = err_var.get('no_param')\n",
    "    stg_path = env_var.get('stg_path')\n",
    "    \n",
    "    fown =stg_path + data_var[module].get('stock_ownership',ENF)\n",
    "    fovr =stg_path + data_var[module].get('stock_overview',ENF)\n",
    "    key = data_var[module].get('stock_key',ENF)\n",
    "    \n",
    "    if (fown==ENF) or (fovr== ENF) or (key == ENF):\n",
    "        e = 'missing file or key name'\n",
    "        log_diagnostics('enrich_data_finviz',e,env_var)\n",
    "        return\n",
    "    \n",
    "    #generate additional attibutes\n",
    "    df_own = pd.read_csv(fown).reset_index()\n",
    "    df_own.set_index(key,inplace=True)\n",
    "    df_view = pd.read_csv(fovr).reset_index()\n",
    "    df_view.set_index(key,inplace=True)\n",
    "    df = pd.merge(df_own,df_view,how='inner',left_index = True, right_index=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "                \n",
    "    transform = get_transform('stg_finviz_summary') \n",
    "    apply_transform(df,transform)\n",
    "    df = df[['Ticker','eps','earnings','P/E','e/p','outstanding_shares']]\n",
    "\n",
    "    df.to_csv(stg_path + 'stock_screener_summary.csv')\n",
    "\n",
    "\n",
    "enrich_data_finviz(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docs():\n",
    "    from pandas_profiling import ProfileReport\n",
    "    env_var, err_var, data_var, transform = unpack_variables(var)\n",
    "    stg_path = env_var.get('stg_path')\n",
    "    ldg_path = env_var.get('ldg_path')\n",
    "    \n",
    "\n",
    "    for i in map_landing_code[module]:\n",
    "        file = i.get('file')\n",
    "        print('# ',file)\n",
    "        # print(i)\n",
    "        df = pd.read_csv(ldg_path + file)\n",
    "        l = list(df.columns)\n",
    "        print('## Columns')\n",
    "        for a in l: \n",
    "            print(a)\n",
    "        print('## Summary Stats')    \n",
    "        print(df.describe(include='object'))\n",
    "        print('')\n",
    "        print('')\n",
    "        profile = ProfileReport(df, title= 'Profile: ' + file + ' (Landing)')\n",
    "        profile.to_file(ldg_path + 'profile_' + file[-3])\n",
    "\n",
    "#generate_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade joblib\n",
    "#!pip install pandas-profiling --user\n",
    "#!pip install <https://github.com/pandas-profiling/pandas-profiling/archive/master.zip> --user\n",
    "#import pandas_profiling as pp\n",
    "#from pandas_profiling import ProfileReport\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
